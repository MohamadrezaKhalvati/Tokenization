{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embedding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embeddings are a type of representation for words in a format that a machine learning model can understand. They are essential in natural language processing (NLP) tasks, as they capture semantic relationships between words and enable machines to process and understand language more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary about Word2Vec corpus:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec is a technique for generating word embeddings, and the quality of these embeddings depends on the corpus it is trained on. The choice of corpus is crucial in ensuring that the model captures a broad and accurate understanding of the language. If you have a specific corpus in mind, you would use Word2Vec to train embeddings tailored to that particular dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\alire\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the path to your CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"./words_pos.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the CSV file using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word</th>\n",
       "      <th>pos_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>aa</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>aaa</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>aah</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>aahed</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>aahing</td>\n",
       "      <td>VBG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    word pos_tag\n",
       "0           0      aa      NN\n",
       "1           1     aaa      NN\n",
       "2           2     aah      NN\n",
       "3           3   aahed     VBN\n",
       "4           4  aahing     VBG"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 370100 entries, 0 to 370099\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  370100 non-null  int64 \n",
      " 1   word        370100 non-null  object\n",
      " 2   pos_tag     370100 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 8.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming there's a 'text' column in your CSV containing the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_corpus = \" \".join(data[\"word\"].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the text into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = word_tokenize(english_corpus.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(\n",
    "    sentences=[tokenized_corpus], vector_size=100, window=5, min_count=1, workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pushing to github, i have  commented this line\n",
    "# word2vec_model.save(\"./word2vec_model_from_corpus.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose 5 words from the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_compare = [\"king\", \"queen\", \"man\", \"woman\", \"computer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the most similar words for each word in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_words_results = {}\n",
    "for word in words_to_compare:\n",
    "    if word in word2vec_model.wv:\n",
    "        similar_words = word2vec_model.wv.most_similar(\n",
    "            word\n",
    "        ) \n",
    "        similar_words_results[word] = similar_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words most similar to 'king': [('platystencephalism', 0.4391556978225708), ('sheol', 0.4329252243041992), ('bodilize', 0.42569977045059204), ('censureship', 0.4167605936527252), ('froust', 0.41011297702789307), ('elacolite', 0.40441256761550903), ('whirlpool', 0.39911168813705444), ('overplacement', 0.3965550363063812), ('laetic', 0.3890400826931), ('conehead', 0.3861731290817261)]\n",
      "Words most similar to 'queen': [('supernumeraries', 0.5076783299446106), ('boxwoods', 0.4479225277900696), ('diminuendoed', 0.4358047544956207), ('cataphysical', 0.43141430616378784), ('dorm', 0.42526260018348694), ('geoethnic', 0.4123079776763916), ('pronely', 0.40865856409072876), ('phoneticohieroglyphic', 0.4074624180793762), ('dauted', 0.40591299533843994), ('emanationism', 0.4045831859111786)]\n",
      "Words most similar to 'man': [('diverged', 0.43074479699134827), ('hepatolysis', 0.4206509292125702), ('thronos', 0.42058518528938293), ('pyrazine', 0.415852814912796), ('hallmark', 0.4139459431171417), ('pribble', 0.41037890315055847), ('matriarchy', 0.407194584608078), ('hebronite', 0.40328121185302734), ('octonematous', 0.3988916575908661), ('barbettes', 0.3888789415359497)]\n",
      "Words most similar to 'woman': [('idoneity', 0.47900065779685974), ('delicti', 0.4628679156303406), ('allocating', 0.44068631529808044), ('antinationally', 0.41756391525268555), ('obliterable', 0.4041658043861389), ('gowdnook', 0.4028528928756714), ('confessors', 0.40148407220840454), ('platypod', 0.398781955242157), ('nincompoophood', 0.39722496271133423), ('gypsoplast', 0.39408543705940247)]\n",
      "Words most similar to 'computer': [('polyaxonic', 0.44603922963142395), ('bocstaff', 0.43480777740478516), ('congregates', 0.4322902262210846), ('scissurella', 0.4302612543106079), ('gentiana', 0.4288415312767029), ('cymblin', 0.4242542088031769), ('decameters', 0.4199448823928833), ('ductilized', 0.41798606514930725), ('clinocephaly', 0.4169696867465973), ('overpraise', 0.41545066237449646)]\n"
     ]
    }
   ],
   "source": [
    "for word, similar_words in similar_words_results.items():\n",
    "    print(f\"Words most similar to '{word}': {similar_words}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
